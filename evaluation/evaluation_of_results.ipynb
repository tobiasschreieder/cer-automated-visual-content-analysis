{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For setup: change working directory to parent and load config for correct paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "os.chdir('..')\n",
    "from config import Config\n",
    "cfg = Config.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, the directory is specified, the files are read and the name column is adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = cfg.output_dir.joinpath('classifier')\n",
    "file_list = os.listdir(file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['name', 'model', 'pred_topic', 'likelihood', 'best_score', 'accuracy', 'precision', 'recall', 'f1', 'f1_weighted', 'parameters'])\n",
    "for file in file_list:\n",
    "    with open(file_dir.joinpath(file)) as f:\n",
    "        d = json.load(f)\n",
    "    record = [d['dataset'], d['model'], d['pred_topic_id'], d['use_likelihood'], d['best_score_f1'], d['eval_metrics']['accuracy'], d['eval_metrics']['precision'], d['eval_metrics']['recall'], d['eval_metrics']['f1'], d['eval_metrics']['f1_weighted'], d['model_params']]\n",
    "    if d['dataset'].count('+') <= 2:\n",
    "        results.loc[len(results)] = record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.name = results['name'].str.split('_').str[1].str.replace('touche', 'google')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General Information about the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_topic</th>\n",
       "      <th>best_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>70.666667</td>\n",
       "      <td>0.739971</td>\n",
       "      <td>0.839352</td>\n",
       "      <td>0.794690</td>\n",
       "      <td>0.688444</td>\n",
       "      <td>0.735698</td>\n",
       "      <td>0.836009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.343547</td>\n",
       "      <td>0.058676</td>\n",
       "      <td>0.044620</td>\n",
       "      <td>0.097990</td>\n",
       "      <td>0.090016</td>\n",
       "      <td>0.087372</td>\n",
       "      <td>0.045651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.653773</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.731424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.692318</td>\n",
       "      <td>0.813889</td>\n",
       "      <td>0.733966</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>0.677662</td>\n",
       "      <td>0.807306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.726090</td>\n",
       "      <td>0.838889</td>\n",
       "      <td>0.781010</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.726136</td>\n",
       "      <td>0.836105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>81.000000</td>\n",
       "      <td>0.796596</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.859539</td>\n",
       "      <td>0.762959</td>\n",
       "      <td>0.819118</td>\n",
       "      <td>0.869111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>81.000000</td>\n",
       "      <td>0.851415</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.965116</td>\n",
       "      <td>0.841584</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.924857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pred_topic  best_score   accuracy  precision     recall         f1  \\\n",
       "count   72.000000   72.000000  72.000000  72.000000  72.000000  72.000000   \n",
       "mean    70.666667    0.739971   0.839352   0.794690   0.688444   0.735698   \n",
       "std     11.343547    0.058676   0.044620   0.097990   0.090016   0.087372   \n",
       "min     55.000000    0.653773   0.722222   0.541667   0.476190   0.555556   \n",
       "25%     55.000000    0.692318   0.813889   0.733966   0.635294   0.677662   \n",
       "50%     76.000000    0.726090   0.838889   0.781010   0.690476   0.726136   \n",
       "75%     81.000000    0.796596   0.870370   0.859539   0.762959   0.819118   \n",
       "max     81.000000    0.851415   0.925926   0.965116   0.841584   0.894737   \n",
       "\n",
       "       f1_weighted  \n",
       "count    72.000000  \n",
       "mean      0.836009  \n",
       "std       0.045651  \n",
       "min       0.731424  \n",
       "25%       0.807306  \n",
       "50%       0.836105  \n",
       "75%       0.869111  \n",
       "max       0.924857  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best five models derived by best_score: (best_score always refers to the f1-score out of the grid searching process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>model</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>best_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>combined</td>\n",
       "      <td>SVC</td>\n",
       "      <td>True</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.89</td>\n",
       "      <td>{'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>combined</td>\n",
       "      <td>SVC</td>\n",
       "      <td>False</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.89</td>\n",
       "      <td>{'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>combined</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>True</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.89</td>\n",
       "      <td>{'alpha': 0.001, 'learning_rate': 'optimal', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>combined</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>False</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.86</td>\n",
       "      <td>{'alpha': 0.001, 'learning_rate': 'optimal', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>google</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>False</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.85</td>\n",
       "      <td>{'alpha': 0.001, 'learning_rate': 'optimal', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name          model  likelihood  best_score  precision  recall    f1  \\\n",
       "63  combined            SVC        True        0.85       0.96    0.84  0.89   \n",
       "62  combined            SVC       False        0.85       0.97    0.82  0.89   \n",
       "45  combined  SGDClassifier        True        0.84       0.96    0.84  0.89   \n",
       "44  combined  SGDClassifier       False        0.84       0.95    0.79  0.86   \n",
       "50    google  SGDClassifier       False        0.83       0.96    0.76  0.85   \n",
       "\n",
       "                                           parameters  \n",
       "63        {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}  \n",
       "62        {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}  \n",
       "45  {'alpha': 0.001, 'learning_rate': 'optimal', '...  \n",
       "44  {'alpha': 0.001, 'learning_rate': 'optimal', '...  \n",
       "50  {'alpha': 0.001, 'learning_rate': 'optimal', '...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[['name', 'model', 'likelihood', 'best_score', 'precision', 'recall', 'f1', 'parameters']].nlargest(5, 'best_score').round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean scores by dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clarifai</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combined</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          best_score  precision  recall    f1\n",
       "name                                         \n",
       "clarifai        0.72       0.76    0.65  0.70\n",
       "combined        0.76       0.81    0.72  0.77\n",
       "google          0.74       0.81    0.69  0.74"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[['name', 'best_score', 'precision', 'recall', 'f1']].groupby(by='name').mean().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best results by combination of likelihood and predicted topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likelihood</th>\n",
       "      <th>pred_topic</th>\n",
       "      <th>best_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>False</td>\n",
       "      <td>55</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>False</td>\n",
       "      <td>76</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>False</td>\n",
       "      <td>81</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>True</td>\n",
       "      <td>55</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>True</td>\n",
       "      <td>76</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>True</td>\n",
       "      <td>81</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   likelihood pred_topic  best_score  precision  recall    f1\n",
       "60      False         55        0.77       0.77    0.75  0.76\n",
       "62      False         76        0.85       0.97    0.82  0.89\n",
       "64      False         81        0.72       0.73    0.68  0.71\n",
       "61       True         55        0.77       0.76    0.74  0.75\n",
       "63       True         76        0.85       0.96    0.84  0.89\n",
       "65       True         81        0.73       0.72    0.68  0.70"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new dfs\n",
    "results_temp = results[['likelihood', 'pred_topic', 'best_score', 'precision', 'recall', 'f1']]\n",
    "results_lt = pd.DataFrame(columns=['likelihood', 'pred_topic', 'best_score', 'precision', 'recall', 'f1'])\n",
    "\n",
    "# get the relevant values for finding the best results for each combination\n",
    "likelihood = results.likelihood.unique()\n",
    "topics = results.pred_topic.unique()\n",
    "\n",
    "# find and concatenate the best results\n",
    "for l in likelihood:\n",
    "    for t in topics:\n",
    "        results_lt = pd.concat([results_lt, results_temp.loc[(results_temp.pred_topic == t) & (results_temp.likelihood == l)].nlargest(1, 'best_score')])\n",
    "        \n",
    "# show the results\n",
    "results_lt.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best combinations of models and topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>pred_topic</th>\n",
       "      <th>best_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>55</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>76</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>81</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PassiveAggressiveClassifier</td>\n",
       "      <td>55</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PassiveAggressiveClassifier</td>\n",
       "      <td>76</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>PassiveAggressiveClassifier</td>\n",
       "      <td>81</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>55</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>76</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>81</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>SVC</td>\n",
       "      <td>55</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>SVC</td>\n",
       "      <td>76</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>SVC</td>\n",
       "      <td>81</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model pred_topic  best_score  precision  recall  \\\n",
       "6    GradientBoostingClassifier         55        0.74       0.78    0.70   \n",
       "8    GradientBoostingClassifier         76        0.82       0.96    0.76   \n",
       "10   GradientBoostingClassifier         81        0.70       0.76    0.60   \n",
       "25  PassiveAggressiveClassifier         55        0.71       0.73    0.69   \n",
       "26  PassiveAggressiveClassifier         76        0.82       0.90    0.81   \n",
       "29  PassiveAggressiveClassifier         81        0.67       0.70    0.66   \n",
       "43                SGDClassifier         55        0.76       0.79    0.70   \n",
       "45                SGDClassifier         76        0.84       0.96    0.84   \n",
       "47                SGDClassifier         81        0.72       0.80    0.65   \n",
       "61                          SVC         55        0.77       0.76    0.74   \n",
       "63                          SVC         76        0.85       0.96    0.84   \n",
       "65                          SVC         81        0.73       0.72    0.68   \n",
       "\n",
       "      f1  \n",
       "6   0.74  \n",
       "8   0.85  \n",
       "10  0.67  \n",
       "25  0.71  \n",
       "26  0.85  \n",
       "29  0.68  \n",
       "43  0.74  \n",
       "45  0.89  \n",
       "47  0.71  \n",
       "61  0.75  \n",
       "63  0.89  \n",
       "65  0.70  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new df\n",
    "results_temp = results[['model', 'pred_topic', 'best_score', 'precision', 'recall', 'f1']]\n",
    "results_mt = pd.DataFrame(columns=['model', 'pred_topic', 'best_score', 'precision', 'recall', 'f1'])\n",
    "\n",
    "# get the relevant values for finding the best results for each combination\n",
    "models = results.model.unique()\n",
    "topics = results.pred_topic.unique()\n",
    "\n",
    "# find and concatenate the best results\n",
    "for m in models:\n",
    "    for t in topics:\n",
    "        results_mt = pd.concat([results_mt, results_temp.loc[(results_temp.pred_topic == t) & (results_temp.model == m)].nlargest(1, 'best_score')])\n",
    "\n",
    "# show the results\n",
    "results_mt.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
